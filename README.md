# Audio-Visual Speech Enhancement (AVSE) | 音频视觉语音增强

## 📌 Table of Contents | 目录
- [English Version](#-english-version) 🇬🇧
- [中文版](#-中文版) 🇨🇳

Please review the [LICENSE.md](LICENSE.md) file for details about project usage and permissions.

---

## 🇬🇧 English Version

Welcome to the **AVSE Project**! 🚀 This project explores the use of `Transformer` models for **Audio-Visual Speech Enhancement**. By leveraging **multimodal learning**, we aim to improve speech clarity and enhance user experience. ✨

### Project Overview
- **Core Concept**: Utilize **Transformer models** to process **Audio + Visual** information for superior speech enhancement. 🎯
- **Technology Stack**: Deep Learning-based **Multimodal Fusion** for robust audio-visual learning. 🧠
- **Ultimate Goal**: Improve speech clarity and optimize perceptual experience. 🎧

### Mixed Audio
This video showcases the mixed audio, which includes both the target speech and background noise.

![Mixed Audio](Audio_for_github/mixed.mp4)

### Enhanced Audio
This video presents the enhanced audio output, where the background noise has been reduced to emphasize the target speech using the AVSE model.

![Enhanced Audio](Audio_for_github/enhanced.mp4)

---

## 🇨🇳 中文版

欢迎来到 **AVSE 项目**！🚀 本项目尝试使用 `Transformer` 模型进行 **音频视觉语音增强**，通过 **多模态学习** 提高语音清晰度和用户体验。✨

### 项目简介
- **核心理念**：利用 **Transformer 模型** 处理 **音频 + 视觉** 信息，实现更优的语音增强效果 🎯
- **技术框架**：基于 **深度学习** 的 **多模态融合** 🧠
- **最终目标**：提升语音清晰度，优化语音感知体验 🎧

